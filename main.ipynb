{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as time\n",
    "from functools import reduce\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9298, 10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = ['065450','013810','005870','010820','003570','119500','103140','012450', \\\n",
    "         '047810', '079550']\n",
    "names = ['빅텍', '스페코','휴니드', '퍼스텍', 'S&T중공업', '포메탈','풍산','한화에어로스페이스', \\\n",
    "         '한국항공우주', 'LIG넥스원']\n",
    "start = '2000-01-01'\n",
    "\n",
    "dfList = []\n",
    "for code in codes:\n",
    "    df = pd.read_csv(code+'_daily.csv', header=0, usecols=[0,1,4], names = \\\n",
    "                      ['Date','open','close'])\n",
    "    df['Date_o'] = [datetime.strptime(str(m),'%Y%m%d')+timedelta(hours=9) for m in df['Date']]\n",
    "    df['Date_c'] = [datetime.strptime(str(m),'%Y%m%d')+timedelta(hours=15) for m in df['Date']]\n",
    "    price_o = pd.DataFrame({'Date': df['Date_o'], code : df['open']})\n",
    "    price_c = pd.DataFrame({'Date': df['Date_c'], code: df['close']})\n",
    "\n",
    "    dfList.append(pd.concat([price_o, price_c], axis=0))    \n",
    "\n",
    "merged = reduce(lambda x, y: pd.merge(x, y, how = 'outer', on = 'Date'),dfList)\n",
    "merged = merged.set_index('Date')\n",
    "merged = merged.sort_index()\n",
    "merged = merged[start:] #원데이터\n",
    "\n",
    "rtn = np.log(merged/merged.shift(1))*100 #수익률 계산\n",
    "\n",
    "rtn.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-152-622aa64b1255>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-152-622aa64b1255>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    def __len__(self):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#customizing dataset\n",
    "\n",
    "class my_data():\n",
    "    \n",
    "    # 데이터 로딩해서 수익률 형태로 변환\n",
    "    # 추후에 원데이터 넣는다면 여기서 코드 바꿔야 함\n",
    "    codes = ['065450','013810','005870','010820','003570','119500','103140','012450', \\\n",
    "             '047810', '079550']\n",
    "    names = ['빅텍', '스페코','휴니드', '퍼스텍', 'S&T중공업', '포메탈','풍산','한화에어로스페이스', \\\n",
    "             '한국항공우주', 'LIG넥스원']\n",
    "    start = '2000-01-01'\n",
    "\n",
    "    dfList = []\n",
    "    for code in codes:\n",
    "        df = pd.read_csv(code+'_daily.csv', header=0, usecols=[0,1,4], names = \\\n",
    "                          ['Date','open','close'])\n",
    "        df['Date_o'] = [datetime.strptime(str(m),'%Y%m%d')+timedelta(hours=9) for m in df['Date']]\n",
    "        df['Date_c'] = [datetime.strptime(str(m),'%Y%m%d')+timedelta(hours=15) for m in df['Date']]\n",
    "        price_o = pd.DataFrame({'Date': df['Date_o'], code : df['open']})\n",
    "        price_c = pd.DataFrame({'Date': df['Date_c'], code: df['close']})\n",
    "\n",
    "        dfList.append(pd.concat([price_o, price_c], axis=0))    \n",
    "\n",
    "    merged = reduce(lambda x, y: pd.merge(x, y, how = 'outer', on = 'Date'),dfList)\n",
    "    merged = merged.set_index('Date')\n",
    "    merged = merged.sort_index()\n",
    "    merged = merged[start:] #원데이터\n",
    "\n",
    "    rtn = np.log(merged/merged.shift(1))*100 #수익률 계산\n",
    "    \n",
    "    def __init__(self, train = True, ratio = 0.7, C = 5):\n",
    "        self.train = train\n",
    "        \n",
    "        if self.train:\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.train_data =[]\n",
    "            self.train_label =[]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            data, target = self.train_data[idx], self.train_label[idx]\n",
    "        else:\n",
    "            data, target = self.test_data[idx], self.test_label[idx]  \n",
    "        return data, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter setting\n",
    "sequence_length = 10\n",
    "input_size = 2 \n",
    "hidden_size = 40\n",
    "num_layers = 2\n",
    "num_classes = 4\n",
    "batch_size = 50\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "\n",
    "train_dataset = my_data(train=True)\n",
    "test_dataset = my_data(train=False)\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset, \n",
    "                               batch_size = batch_size, shuffle = False)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset, \n",
    "                               batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model setting: encoder\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # architecture\n",
    "        self.embed = nn.Embedding(vocab_size, EMBED_SIZE, padding_idx = PAD_IDX)\n",
    "        self.rnn = nn.GRU( # LSTM or GRU\n",
    "            input_size = EMBED_SIZE,\n",
    "            hidden_size = HIDDEN_SIZE // NUM_DIRS,\n",
    "            num_layers = NUM_LAYERS,\n",
    "            bias = True,\n",
    "            batch_first = True,\n",
    "            dropout = DROPOUT,\n",
    "            bidirectional = BIDIRECTIONAL\n",
    "        )\n",
    "\n",
    "        if CUDA:\n",
    "            self = self.cuda()\n",
    "\n",
    "    def init_hidden(self, rnn_type): # initialize hidden states\n",
    "        h = zeros(NUM_LAYERS * NUM_DIRS, BATCH_SIZE, HIDDEN_SIZE // NUM_DIRS) # hidden states\n",
    "        if rnn_type == \"LSTM\":\n",
    "            c = zeros(NUM_LAYERS * NUM_DIRS, BATCH_SIZE, HIDDEN_SIZE // NUM_DIRS) # cell states\n",
    "            return (h, c)\n",
    "        return h\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        self.hidden = self.init_hidden(\"GRU\") # LSTM or GRU\n",
    "        x = self.embed(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, mask[1], batch_first = True)\n",
    "        h, _ = self.rnn(x, self.hidden)\n",
    "        h, _ = nn.utils.rnn.pad_packed_sequence(h, batch_first = True)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
